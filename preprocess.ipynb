{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\n",
      "pip 19.0.3 from /Users/bryanwu/anaconda/lib/python3.7/site-packages/pip (python 3.7)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python --version\n",
    "pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanwu/anaconda/envs/Tensorflow/lib/python3.7/site-packages/apache_beam/__init__.py:84: UserWarning: Some syntactic constructs of Python 3 are not yet fully supported by Apache Beam.\n",
      "  'Some syntactic constructs of Python 3 are not yet fully supported by '\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from math import sin, cos, atan2, sqrt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam.impl as tft_beam\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import os\n",
    "from tensorflow_transform.coders import example_proto_coder\n",
    "from apache_beam.io import tfrecordio\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessCSV(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        key, fare_amount, pickup_datetime, pickup_longitude, pickup_latitude, \\\n",
    "        dropoff_longitude, dropoff_latitude, passenger_count = element.split(',')\n",
    "        return [{\n",
    "            'fare_amount': fare_amount,\n",
    "            'pickup_datetime': pickup_datetime,\n",
    "            'pickup_longitude': pickup_longitude,\n",
    "            'pickup_latitude': pickup_latitude,\n",
    "            'dropoff_longitude': dropoff_longitude,\n",
    "            'dropoff_latitude': dropoff_latitude\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateDistance(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        pickup_longitude = float(element['pickup_longitude'])\n",
    "        pickup_latitude = float(element['pickup_latitude'])\n",
    "        dropoff_longitude = float(element['dropoff_longitude'])\n",
    "        dropoff_latitude = float(element['dropoff_latitude'])\n",
    "        del_longitude = pickup_longitude - dropoff_longitude\n",
    "        del_latitude = pickup_latitude - dropoff_latitude\n",
    "        a = sin(del_latitude/2)**2 + cos(pickup_latitude)*cos(dropoff_latitude)*sin(del_longitude/2)**2\n",
    "        c = 2*atan2(sqrt(a), sqrt(1-a))\n",
    "        R = 6371.0\n",
    "        d = R * c\n",
    "        element['distance'] = d\n",
    "        return [element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterNoisyDataPoint(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        def is_within_boundingbox(element, BB=(-74.5, -72.8, 40.5, 41.8)):\n",
    "            pickup_longitude = float(element['pickup_longitude'])\n",
    "            pickup_latitude = float(element['pickup_latitude'])\n",
    "            dropoff_longitude = float(element['dropoff_longitude'])\n",
    "            dropoff_latitude = float(element['dropoff_latitude'])\n",
    "            return (pickup_longitude >= BB[0]) & (pickup_longitude <= BB[1]) & \\\n",
    "                   (pickup_latitude >= BB[2]) & (pickup_latitude <= BB[3]) & \\\n",
    "                   (dropoff_longitude >= BB[0]) & (dropoff_longitude <= BB[1]) & \\\n",
    "                   (dropoff_latitude >= BB[2]) & (dropoff_latitude <= BB[3])\n",
    "        \n",
    "        if is_within_boundingbox(element):\n",
    "            return [element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractDateTime(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        dt = datetime.strptime(element['pickup_datetime'], '%Y-%m-%d %H:%M:%S UTC')\n",
    "        element['hour'] = dt.hour\n",
    "        element['month'] = dt.month\n",
    "        element['week_number'] = dt.isocalendar()[1]\n",
    "        element['weekday'] = dt.weekday()\n",
    "        return [element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeToString(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        column_names = ['fare_amount', \n",
    "                        'week_number', \n",
    "                        'weekday', 'hour', \n",
    "                        'pickup_longitude', \n",
    "                        'pickup_latitude', \n",
    "                        'dropoff_longitude',\n",
    "                        'dropoff_latitude',\n",
    "                        'distance']\n",
    "        \n",
    "        return [','.join(['{}']*len(column_names)).format(*[element[column] for column in column_names])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(element):\n",
    "    fare_amount = element['fare_amount']\n",
    "    pickup_longitude = tft.scale_to_0_1(element['pickup_longitude'])\n",
    "    pickup_latitude = tft.scale_to_0_1(element['pickup_latitude'])\n",
    "    dropoff_longitude = tft.scale_to_0_1(element['dropoff_longitude'])\n",
    "    dropoff_latitude = tft.scale_to_0_1(element['dropoff_latitude'])\n",
    "    distance = tft.scale_to_0_1(element['distance'])\n",
    "    hour = element['hour']\n",
    "    month = element['month']\n",
    "    week_number = element['week_number']\n",
    "    weekday = element['weekday']\n",
    "    return {\n",
    "            'fare_amount': fare_amount,\n",
    "            'pickup_longitude': pickup_longitude,\n",
    "            'pickup_latitude': pickup_latitude,\n",
    "            'dropoff_longitude': dropoff_longitude,\n",
    "            'dropoff_latitude': dropoff_latitude,\n",
    "            'distance': distance,\n",
    "            'hour': hour,\n",
    "            'month' : month,\n",
    "            'week_number': week_number,\n",
    "            'weekday': weekday\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = PipelineOptions(\n",
    "    runner='direct'\n",
    ")\n",
    "pipe = beam.Pipeline(options=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/bryanwu/anaconda/envs/Tensorflow/lib/python3.7/site-packages/tensorflow_transform/mappers.py:117: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/bryanwu/anaconda/envs/Tensorflow/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /var/folders/wt/dv0qlxcn5j9b0h9vd8tr23bh0000gn/T/tmplwh7_83u/tftransform_tmp/802458ea30774a659a41d9313a9bd37e/saved_model.pb\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /var/folders/wt/dv0qlxcn5j9b0h9vd8tr23bh0000gn/T/tmplwh7_83u/tftransform_tmp/1bb4da4af7dd4123b850ec9c1d49e5eb/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "file_location = './new-york-city-taxi-fare-prediction/train_subset.csv'\n",
    "column_names = ['fare_amount', \n",
    "                'week_number', \n",
    "                'weekday', \n",
    "                'hour', \n",
    "                'month',\n",
    "                'pickup_longitude', \n",
    "                'pickup_latitude', \n",
    "                'dropoff_longitude',\n",
    "                'dropoff_latitude',\n",
    "                'distance']\n",
    "\n",
    "raw_data = (\n",
    "        pipe \n",
    "         | 'ReadFile' >> beam.io.ReadFromText(file_location, skip_header_lines=1)\n",
    "         | 'SplitCSV' >> beam.ParDo(ProcessCSV())\n",
    "         | 'CalculateDistance' >> beam.ParDo(CalculateDistance())\n",
    "         | 'FilterNoisyDataPoints' >> beam.ParDo(FilterNoisyDataPoint())\n",
    "         | 'ExtractDateTime' >> beam.ParDo(ExtractDateTime())\n",
    "#          | 'MergeToString' >> beam.ParDo(MergeToString())\n",
    "#          | 'WriteToGCS' >> beam.io.WriteToText('./tmp/transformed_train.csv', header=', '.join(column_names))\n",
    "        )\n",
    "\n",
    "raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.from_feature_spec({\n",
    "            'fare_amount': tf.FixedLenFeature([], tf.float32),\n",
    "            'pickup_longitude': tf.FixedLenFeature([], tf.float32),\n",
    "            'pickup_latitude': tf.FixedLenFeature([], tf.float32),\n",
    "            'dropoff_longitude': tf.FixedLenFeature([], tf.float32),\n",
    "            'dropoff_latitude': tf.FixedLenFeature([], tf.float32),\n",
    "            'distance': tf.FixedLenFeature([], tf.float32),\n",
    "            'hour': tf.FixedLenFeature([], tf.int64),\n",
    "            'month': tf.FixedLenFeature([], tf.int64),\n",
    "            'week_number': tf.FixedLenFeature([], tf.int64),\n",
    "            'weekday': tf.FixedLenFeature([], tf.int64)\n",
    "}))\n",
    "\n",
    "\n",
    "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "    dataset_and_metadata, transform_fn = (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(\n",
    "                normalize)\n",
    "    \n",
    "    dataset, metadata = dataset_and_metadata\n",
    "    eval_percent = 10\n",
    "    train_dataset, eval_dataset = (\n",
    "        dataset\n",
    "        | 'Split dataset' >> beam.Partition(\n",
    "            lambda elem, _: int(random.uniform(0, 100) < eval_percent), 2))\n",
    "    \n",
    "    coder = example_proto_coder.ExampleProtoCoder(metadata.schema)\n",
    "    \n",
    "    \n",
    "    train_dataset_dir = os.path.join('dataset', 'train')\n",
    "    eval_dataset_dir = os.path.join('dataset', 'eval')\n",
    "    work_dir = os.path.join('dataset', 'transform_fn')\n",
    "    \n",
    "    train_dataset_prefix = os.path.join(train_dataset_dir, 'train')\n",
    "    _ = (\n",
    "        train_dataset\n",
    "        | 'Write train dataset' >> tfrecordio.WriteToTFRecord(\n",
    "            train_dataset_prefix, coder))\n",
    "\n",
    "    eval_dataset_prefix = os.path.join(eval_dataset_dir, 'eval')\n",
    "    _ = (\n",
    "        eval_dataset\n",
    "        | 'Write eval dataset' >> tfrecordio.WriteToTFRecord(\n",
    "            eval_dataset_prefix, coder))\n",
    "\n",
    "    # Write the transform_fn\n",
    "    _ = (\n",
    "        transform_fn\n",
    "        | 'Write transformFn' >> transform_fn_io.WriteTransformFn(work_dir))\n",
    "    # [END dataflow_molecules_write_tfrecords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /var/folders/wt/dv0qlxcn5j9b0h9vd8tr23bh0000gn/T/tmplwh7_83u/tftransform_tmp/b6789422d4de40fca7068005985dfc1a/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /var/folders/wt/dv0qlxcn5j9b0h9vd8tr23bh0000gn/T/tmplwh7_83u/tftransform_tmp/b6789422d4de40fca7068005985dfc1a/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:root:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.RunnerResult at 0xb3bc3a1d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
